# -*- coding: utf-8 -*-
"""memes_glucose.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s97mmkzUXet3J8Yf_b-WvxuaimtqTaYX
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import joblib

# Required imports
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ==============================================================================
# --- Master Configuration ---
# ==============================================================================

# --- Get the directory of the current script ---
# This assumes the script is run from its own directory or that the paths are relative to the script's location
CURRENT_SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# If the script is run directly without being in its own directory, __file__ might not be available or might be relative.
# A more robust way if running from anywhere:
if '__file__' in locals():
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
else:
    BASE_DIR = os.getcwd() # Fallback to current working directory

# --- Session 1 Paths & Info ---
# Assuming data is in ../eigen_blood/first_session/ relative to the script's location
S1_FNIRS_PATH = os.path.join(BASE_DIR, './first_fnirs_log.csv')
S1_CGM_PATH = os.path.join(BASE_DIR, './first_cgm_log.csv')
S1_CGM_COLUMN = 'Scan Glucose (mmol/L)'

# --- Session 2 Paths & Info ---
# Assuming data is in ../eigen_blood/second_session/ relative to the script's location
S2_FNIRS_PATH = os.path.join(BASE_DIR, './second_fnirs_log.csv')
S2_CGM_PATH = os.path.join(BASE_DIR, './second_cgm_log.csv')
S2_CGM_COLUMN = 'Scan Glucose (mmol/L)'

# --- Shared ML & Processing Constants ---
SMOOTHING_WINDOW = 30; EPOCH_DURATION_S = 60; EPOCH_OVERLAP_RATIO = 0.5; N_FEATURES_TO_SELECT = 40
N_CV_SPLITS = 5; CV_GAP_EPOCHS = 2
USABLE_CHANNELS = [
    (2,5,'short'),(3,6,'short'),(6,12,'short'),(7,13,'short'),(1,2,'long'),(1,6,'long'),(1,9,'long'),
    (2,6,'long'),(2,7,'long'),(3,5,'long'),(3,7,'long'),(4,2,'long'),(4,5,'long'),(4,6,'long'),
    (4,7,'long'),(5,6,'long'),(5,9,'long'),(5,12,'long'),(6,3,'long'),(6,5,'long'),(6,13,'long'),
    (7,3,'long'),(7,9,'long'),(7,12,'long'),(8,2,'long'),(8,3,'long'),(8,11,'long'),(8,13,'long'),
]
DPF_WL1=6.25; DPF_WL2=4.89; D_SHORT_CM=0.8; D_LONG_CM=3.0; LN10=np.log(10)
EXT_MOLAR_HBO_WL1=803.1/LN10; EXT_MOLAR_HHB_WL1=2278.1/LN10; EXT_MOLAR_HBO_WL2=1058.0/LN10; EXT_MOLAR_HHB_WL2=740.0/LN10
EPS_HBO_WL1_uM=EXT_MOLAR_HBO_WL1/1.0e6; EPS_HHB_WL1_uM=EXT_MOLAR_HHB_WL1/1.0e6; EPS_HBO_WL2_uM=EXT_MOLAR_HBO_WL2/1.0e6; EPS_HHB_WL2_uM=EXT_MOLAR_HHB_WL2/1.0e6
E_MATRIX_uM=np.array([[EPS_HBO_WL1_uM,EPS_HHB_WL1_uM],[EPS_HBO_WL2_uM,EPS_HHB_WL2_uM]])
try: E_INV_MATRIX_uM=np.linalg.inv(E_MATRIX_uM)
except np.linalg.LinAlgError: print("FATAL ERROR: Extinction coefficient matrix is singular."); exit()

# ==============================================================================
# --- Helper Functions and Classes ---
# ==============================================================================
def plot_clarke_error_grid(y_true_mmol, y_pred_mmol, title, plots_folder):
    y_true = np.array(y_true_mmol) * 18.0182; y_pred = np.array(y_pred_mmol) * 18.0182
    fig, ax = plt.subplots(figsize=(10, 10)); ax.scatter(y_true, y_pred, c='k', s=25, zorder=2)
    ax.set_xlabel("Reference Glucose (mg/dL)", fontsize=14); ax.set_ylabel("Predicted Glucose (mg/dL)", fontsize=14)
    ax.set_title(title, fontsize=16); ax.set_xticks(range(0, 401, 50)); ax.set_yticks(range(0, 401, 50))
    ax.set_xlim(0, 400); ax.set_ylim(0, 400); ax.set_facecolor('whitesmoke'); ax.grid(True, linestyle='--', color='lightgray')
    ax.set_aspect('equal', adjustable='box'); x = np.arange(0, 401); ax.plot(x, x, 'k-', lw=1.5, zorder=1)
    ax.plot([0, 400],[70, 70],'k--'); ax.plot([70, 70],[0, 400],'k--'); ax.plot([0, 400],[180, 180],'k--'); ax.plot([180, 180],[0, 400],'k--')
    zone_counts = {'A':0,'B':0,'C':0,'D':0,'E':0}; total_points = len(y_true)
    for true, pred in zip(y_true, y_pred):
        if (abs(true - pred) / true < 0.2) or (true < 70 and pred < 70): zone_counts['A'] += 1
        elif (true >= 70 and pred <= 50) or (true <= 70 and pred >= 180): zone_counts['D'] += 1
        elif (true > 180 and pred < 70) or (true < 70 and pred > 180): zone_counts['E'] += 1
        else: zone_counts['B'] += 1
    print("\n--- Clarke Error Grid Analysis ---")
    if total_points > 0:
        for z, c in zone_counts.items(): print(f"  Zone {z}: {c}/{total_points} ({(c/total_points)*100:.2f}%)")
    fig.savefig(os.path.join(plots_folder, f"ClarkeGrid_{title.replace(' ', '_').replace(':', '')}.png"), dpi=150)
    plt.show()

class BlockedKFold():
    def __init__(self, n_splits=5, gap=0): self.n_splits, self.gap = n_splits, gap
    def split(self, X, y=None, groups=None):
        n, k_size = len(X), len(X)//self.n_splits; ids = np.arange(n)
        for i in range(self.n_splits):
            s,e = i*k_size, (i+1)*k_size; test=ids[s:e]; train_before=ids[0:max(0,s-self.gap)]; train_after=ids[min(n,e+self.gap):n]
            yield np.concatenate([train_before,train_after]), test

def preprocess_and_feature_engineer(fnirs_path, cgm_path, cgm_column):
    df_fnirs = pd.read_csv(fnirs_path); df_fnirs.columns = df_fnirs.columns.str.strip()
    df_cgm = pd.read_csv(cgm_path); df_cgm.columns = df_cgm.columns.str.strip()
    df_cgm['datetime'] = pd.to_datetime(df_cgm['Device Timestamp'], dayfirst=True)
    df_cgm = df_cgm.sort_values(by='datetime').reset_index(drop=True)
    first_cgm_time = df_cgm['datetime'].iloc[0]
    df_cgm['Time_sec'] = (df_cgm['datetime'] - first_cgm_time).dt.total_seconds()
    df_fnirs['glucose'] = np.interp(x=df_fnirs['Time'], xp=df_cgm['Time_sec'], fp=df_cgm[cgm_column])
    for s, d, ctype in USABLE_CHANNELS:
        pmode, dval = ('LP',D_SHORT_CM) if ctype=='short' else ('RP',D_LONG_CM)
        cid, c740, c850 = f"S{s}_D{d}_{pmode}", f'S{s}_D{d}_740nm_{pmode}', f'S{s}_D{d}_850nm_{pmode}'
        if c740 not in df_fnirs.columns or c850 not in df_fnirs.columns: continue
        od740 = -np.log10(np.maximum(df_fnirs[c740]/np.nanmean(df_fnirs[c740]),1e-9))
        od850 = -np.log10(np.maximum(df_fnirs[c850]/np.nanmean(df_fnirs[c850]),1e-9))
        hbo, hbr = (E_INV_MATRIX_uM @ np.vstack((od740/(dval*DPF_WL1), od850/(dval*DPF_WL2))))
        df_fnirs[f'{cid}_dHbO_s'] = pd.Series(hbo).rolling(SMOOTHING_WINDOW,center=True,min_periods=1).mean()
        df_fnirs[f'{cid}_dHbR_s'] = pd.Series(hbr).rolling(SMOOTHING_WINDOW,center=True,min_periods=1).mean()
    hb_cols = [c for c in df_fnirs.columns if '_dHb' in c and '_s' in c]; sr = 1/df_fnirs['Time'].diff().mean()
    samples_epoch = int(EPOCH_DURATION_S*sr); step = int(samples_epoch*(1-EPOCH_OVERLAP_RATIO))
    epochs, labels = [], []
    for i in range(0, len(df_fnirs) - samples_epoch + 1, step):
        epoch_df = df_fnirs.iloc[i:i+samples_epoch]; features = {}
        for col in hb_cols:
            s = epoch_df[col].dropna(); f = {'mean':s.mean(),'std':s.std(),'skew':s.skew(),'kurtosis':s.kurtosis(),'max_minus_min':s.max()-s.min()}
            for k,v in f.items(): features[f'{col}_{k}'] = v
        epochs.append(features); labels.append(epoch_df['glucose'].mean())
    X = pd.DataFrame(epochs); y = np.array(labels); X.dropna(axis=1, how='all', inplace=True); X.fillna(X.mean(), inplace=True)
    return X, y, sr

def run_generalization_experiment(train_fnirs_path, train_cgm_path, train_cgm_col, test_fnirs_path, test_cgm_path, test_cgm_col, experiment_name):
    """
    Runs a full train-and-test experiment, including model selection, training, prediction, and evaluation.
    """
    # --- Setup for this specific experiment ---
    plots_folder = os.path.join(BASE_DIR, f"PLOTS_{experiment_name}") # Create plots folder in the script's directory
    model_save_path = os.path.join(plots_folder, f"best_model_{experiment_name}.joblib")
    os.makedirs(plots_folder, exist_ok=True)

    # === PART A: TRAIN AND SELECT BEST MODEL ===
    print("="*70 + f"\n--- EXPERIMENT: {experiment_name} ---\n" + "="*70)
    print("\n--- PART A: Training and Selecting Model ---")
    X_train, y_train, _ = preprocess_and_feature_engineer(train_fnirs_path, train_cgm_path, train_cgm_col)
    print(f"Training data processed. X shape: {X_train.shape}, y shape: {y_train.shape}")

    models_to_test = {"Ridge": Ridge(alpha=10), "RandomForest": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)}
    bkf = BlockedKFold(n_splits=N_CV_SPLITS, gap=CV_GAP_EPOCHS); cv_scores = {}

    print("\n--- Cross-validating models on training data... ---")
    for name, model in models_to_test.items():
        pipeline = Pipeline([('scaler', StandardScaler()), ('selector', SelectKBest(f_regression, k=min(N_FEATURES_TO_SELECT, X_train.shape[1]))), ('regressor', model)])
        y_true_cv, y_pred_cv = [], []
        for train_idx, test_idx in bkf.split(X_train):
            pipeline.fit(X_train.iloc[train_idx], y_train[train_idx]); y_pred_cv.extend(pipeline.predict(X_train.iloc[test_idx])); y_true_cv.extend(y_train[test_idx])
        cv_scores[name] = r2_score(y_true_cv, y_pred_cv)
        print(f"  {name} - Within-Session Cross-Validated RÂ²: {cv_scores[name]:.3f}")

    best_model_name = max(cv_scores, key=cv_scores.get)
    print(f"\n--- Best model is '{best_model_name}'. Retraining on ALL training data... ---")
    best_model_pipeline = Pipeline([('scaler', StandardScaler()), ('selector', SelectKBest(f_regression, k=min(N_FEATURES_TO_SELECT, X_train.shape[1]))), ('regressor', models_to_test[best_model_name])])
    best_model_pipeline.fit(X_train, y_train)
    joblib.dump(best_model_pipeline, model_save_path)
    print(f"Final model saved to: {model_save_path}")

    # === PART B: TEST BEST MODEL ON NEW DATA ===
    print("\n--- PART B: Testing Model on New Session Data ---")
    final_model = joblib.load(model_save_path)
    X_test, y_test_true, sr_test = preprocess_and_feature_engineer(test_fnirs_path, test_cgm_path, test_cgm_col)
    print(f"Test data processed. X shape: {X_test.shape}, y shape: {y_test_true.shape}")

    print("\n--- Predicting on test data and evaluating performance... ---")
    y_test_pred = final_model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred)); mae = mean_absolute_error(y_test_true, y_test_pred); r2 = r2_score(y_test_true, y_test_pred)

    print("\n--- Generalization Performance Metrics ---")
    print(f"  Root Mean Squared Error (RMSE): {rmse:.3f} mmol/L")
    print(f"  Mean Absolute Error (MAE):      {mae:.3f} mmol/L")
    print(f"  R-squared (RÂ²):                 {r2:.3f}")

    print("\n--- Generating final evaluation plots... ---")
    plot_clarke_error_grid(y_test_true, y_test_pred, f"Test: {experiment_name}", plots_folder)

    epoch_time_axis_sec = np.arange(len(y_test_true)) * (EPOCH_DURATION_S * (1-EPOCH_OVERLAP_RATIO))
    plt.figure(figsize=(16, 7)); plt.plot(epoch_time_axis_sec/60, y_test_true, 'o-', label=f'True Glucose (Test Data)', color='dodgerblue')
    plt.plot(epoch_time_axis_sec/60, y_test_pred, 'o-', label=f'Predicted Glucose ({best_model_name})', color='purple', alpha=0.8)
    plt.title(f"Generalization Test: {experiment_name}", fontsize=16); plt.xlabel('Time (minutes)'); plt.ylabel('Glucose (mmol/L)'); plt.legend(); plt.grid(True)
    plt.savefig(os.path.join(plots_folder, f"Timeseries_{experiment_name}.png"), dpi=150); plt.show()

    plt.figure(figsize=(8, 8)); sns.scatterplot(x=y_test_true, y=y_test_pred, alpha=0.7)
    min_val, max_val = min(y_test_true.min(), y_test_pred.min()), max(y_test_true.max(), y_test_pred.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')
    plt.title(f'Test: {experiment_name}', fontsize=16); plt.xlabel('True Glucose (mmol/L)'); plt.ylabel('Predicted Glucose (mmol/L)'); plt.legend(); plt.grid(True)
    plt.savefig(os.path.join(plots_folder, f"Scatter_{experiment_name}.png"), dpi=150); plt.show()
    print("-" * 70)


# ==============================================================================
# --- Main Execution: Run Both Experiments ---
# ==============================================================================
if __name__ == "__main__":
    # --- Experiment 1: Train on Session 1, Test on Session 2 ---
    run_generalization_experiment(
        train_fnirs_path=S1_FNIRS_PATH, train_cgm_path=S1_CGM_PATH, train_cgm_col=S1_CGM_COLUMN,
        test_fnirs_path=S2_FNIRS_PATH, test_cgm_path=S2_CGM_PATH, test_cgm_col=S2_CGM_COLUMN,
        experiment_name="Train_S1_Test_S2"
    )

    # --- Experiment 2: Train on Session 2, Test on Session 1 ---
    run_generalization_experiment(
        train_fnirs_path=S2_FNIRS_PATH, train_cgm_path=S2_CGM_PATH, train_cgm_col=S2_CGM_COLUMN,
        test_fnirs_path=S1_FNIRS_PATH, test_cgm_path=S1_CGM_PATH, test_cgm_col=S1_CGM_COLUMN,
        experiment_name="Train_S2_Test_S1"
    )

    print("\n\nAll experiments complete!")

"""# Part 2

test on 30+30 sequentially, train on 140%

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import joblib

# Add Ridge regression import
from sklearn.linear_model import Ridge

# Required imports
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ==============================================================================
# --- Master Configuration ---
# ==============================================================================

# --- Get the directory of the current script ---
if '__file__' in locals():
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
else:
    BASE_DIR = os.getcwd() # Fallback to current working directory

# --- File Paths & Info ---
# Assuming data is in the current directory (data_and_python) relative to the script's location
S1_FNIRS_PATH = os.path.join(BASE_DIR, 'first_fnirs_log.csv')
S1_CGM_PATH = os.path.join(BASE_DIR, 'first_cgm_log.csv')
S1_CGM_COLUMN = 'Scan Glucose (mmol/L)'

S2_FNIRS_PATH = os.path.join(BASE_DIR, 'second_fnirs_log.csv')
S2_CGM_PATH = os.path.join(BASE_DIR, 'second_cgm_log.csv')
S2_CGM_COLUMN = 'Scan Glucose (mmol/L)'


# --- ML & Processing Constants ---
TRAIN_SPLIT_RATIO = 0.7 # Use the first 70% of each session for training
SMOOTHING_WINDOW = 30; EPOCH_DURATION_S = 60; EPOCH_OVERLAP_RATIO = 0.5; N_FEATURES_TO_SELECT = 40
USABLE_CHANNELS = [
    (2,5,'short'),(3,6,'short'),(6,12,'short'),(7,13,'short'),(1,2,'long'),(1,6,'long'),(1,9,'long'),
    (2,6,'long'),(2,7,'long'),(3,5,'long'),(3,7,'long'),(4,2,'long'),(4,5,'long'),(4,6,'long'),
    (4,7,'long'),(5,6,'long'),(5,9,'long'),(5,12,'long'),(6,3,'long'),(6,5,'long'),(6,13,'long'),
    (7,3,'long'),(7,9,'long'),(7,12,'long'),(8,2,'long'),(8,3,'long'),(8,11,'long'),(8,13,'long'),
]
DPF_WL1=6.25; DPF_WL2=4.89; D_SHORT_CM=0.8; D_LONG_CM=3.0; LN10=np.log(10)
EXT_MOLAR_HBO_WL1=803.1/LN10; EXT_MOLAR_HHB_WL1=2278.1/LN10; EXT_MOLAR_HBO_WL2=1058.0/LN10; EXT_MOLAR_HHB_WL2=740.0/LN10
EPS_HBO_WL1_uM=EXT_MOLAR_HBO_WL1/1.0e6; EPS_HHB_WL1_uM=EXT_MOLAR_HHB_WL1/1.0e6; EPS_HBO_WL2_uM=EXT_MOLAR_HBO_WL2/1.0e6; EPS_HHB_WL2_uM=EXT_MOLAR_HHB_WL2/1.0e6
E_MATRIX_uM=np.array([[EPS_HBO_WL1_uM,EPS_HHB_WL1_uM],[EPS_HBO_WL2_uM,EPS_HHB_WL2_uM]])
try: E_INV_MATRIX_uM=np.linalg.inv(E_MATRIX_uM)
except np.linalg.LinAlgError: print("FATAL ERROR: Extinction coefficient matrix is singular."); exit()
PLOTS_FOLDER = os.path.join(BASE_DIR, "fNIRS_CombinedTraining_Results") # Create plots folder in the script's directory
os.makedirs(PLOTS_FOLDER, exist_ok=True)

# ==============================================================================
# --- Helper Functions (Identical to previous script) ---
# ==============================================================================
def plot_clarke_error_grid(y_true_mmol, y_pred_mmol, title, plots_folder):
    y_true=np.array(y_true_mmol)*18.0182; y_pred=np.array(y_pred_mmol)*18.0182; fig,ax=plt.subplots(figsize=(10,10)); ax.scatter(y_true,y_pred,c='k',s=25,zorder=2); ax.set_xlabel("Reference Glucose (mg/dL)"); ax.set_ylabel("Predicted Glucose (mg/dL)"); ax.set_title(title,fontsize=16); ax.set_xticks(range(0,401,50)); ax.set_yticks(range(0,401,50)); ax.set_xlim(0,400); ax.set_ylim(0,400); ax.set_facecolor('whitesmoke'); ax.grid(True,linestyle='--',color='lightgray'); ax.set_aspect('equal',adjustable='box'); x=np.arange(0,401); ax.plot(x,x,'k-',lw=1.5,zorder=1); ax.plot([0,400],[70,70],'k--'); ax.plot([70,70],[0,400],'k--'); ax.plot([0,400],[180,180],'k--'); ax.plot([180,180],[0,400],'k--'); zone_counts={'A':0,'B':0,'C':0,'D':0,'E':0}; total_points=len(y_true)
    for true,pred in zip(y_true,y_pred):
        if(abs(true-pred)/true<0.2)or(true<70 and pred<70):zone_counts['A']+=1
        elif(true>=70 and pred<=50)or(true<=70 and pred>=180):zone_counts['D']+=1
        elif(true>180 and pred<70)or(true<70 and pred>180):zone_counts['E']+=1
        else:zone_counts['B']+=1
    print("\n--- Clarke Error Grid Analysis ---")
    if total_points>0:
        for z,c in zone_counts.items(): print(f"  Zone {z}: {c}/{total_points} ({(c/total_points)*100:.2f}%)")
    fig.savefig(os.path.join(plots_folder,f"ClarkeGrid_{title.replace(' ','_').replace(':','')}.png"),dpi=150); plt.show()

def preprocess_and_feature_engineer(fnirs_path, cgm_path, cgm_column):
    df_fnirs = pd.read_csv(fnirs_path); df_fnirs.columns = df_fnirs.columns.str.strip()
    df_cgm = pd.read_csv(cgm_path); df_cgm.columns = df_cgm.columns.str.strip()
    df_cgm['datetime'] = pd.to_datetime(df_cgm['Device Timestamp'], dayfirst=True); df_cgm = df_cgm.sort_values(by='datetime').reset_index(drop=True)
    first_cgm_time = df_cgm['datetime'].iloc[0]; df_cgm['Time_sec'] = (df_cgm['datetime']-first_cgm_time).dt.total_seconds()
    df_fnirs['glucose'] = np.interp(x=df_fnirs['Time'], xp=df_cgm['Time_sec'], fp=df_cgm[cgm_column])
    for s,d,ctype in USABLE_CHANNELS:
        pmode,dval=('LP',D_SHORT_CM) if ctype=='short' else ('RP',D_LONG_CM); cid,c740,c850=f"S{s}_D{d}_{pmode}",f'S{s}_D{d}_740nm_{pmode}',f'S{s}_D{d}_850nm_{pmode}'
        if c740 not in df_fnirs.columns or c850 not in df_fnirs.columns: continue
        od740=-np.log10(np.maximum(df_fnirs[c740]/np.nanmean(df_fnirs[c740]),1e-9)); od850=-np.log10(np.maximum(df_fnirs[c850]/np.nanmean(df_fnirs[c850]),1e-9))
        hbo,hbr=(E_INV_MATRIX_uM@np.vstack((od740/(dval*DPF_WL1),od850/(dval*DPF_WL2))))
        df_fnirs[f'{cid}_dHbO_s']=pd.Series(hbo).rolling(SMOOTHING_WINDOW,center=True,min_periods=1).mean()
        df_fnirs[f'{cid}_dHbR_s']=pd.Series(hbr).rolling(SMOOTHING_WINDOW,center=True,min_periods=1).mean()
    hb_cols=[c for c in df_fnirs.columns if '_dHb' in c and '_s' in c]; sr=1/df_fnirs['Time'].diff().mean()
    samples_epoch=int(EPOCH_DURATION_S*sr); step=int(samples_epoch*(1-EPOCH_OVERLAP_RATIO))
    epochs,labels=[],[]
    for i in range(0,len(df_fnirs)-samples_epoch+1,step):
        epoch_df=df_fnirs.iloc[i:i+samples_epoch]; features={}
        for col in hb_cols:
            s=epoch_df[col].dropna(); f={'mean':s.mean(),'std':s.std(),'skew':s.skew(),'kurtosis':s.kurtosis(),'max_minus_min':s.max()-s.min()}
            for k,v in f.items(): features[f'{col}_{k}']=v
        epochs.append(features); labels.append(epoch_df['glucose'].mean())
    X=pd.DataFrame(epochs); y=np.array(labels); X.dropna(axis=1,how='all',inplace=True); X.fillna(X.mean(),inplace=True)
    return X,y,sr

# ==============================================================================
# --- Main Experiment Logic ---
# ==============================================================================

# --- Part A: Data Preparation and Splitting ---
print("="*60 + "\n--- PART A: Preparing and Splitting Data from Both Sessions ---\n" + "="*60)
X_s1, y_s1, sr_s1 = preprocess_and_feature_engineer(S1_FNIRS_PATH, S1_CGM_PATH, S1_CGM_COLUMN)
X_s2, y_s2, sr_s2 = preprocess_and_feature_engineer(S2_FNIRS_PATH, S2_CGM_PATH, S2_CGM_COLUMN)
print(f"Processed Session 1: {X_s1.shape[0]} epochs")
print(f"Processed Session 2: {X_s2.shape[0]} epochs")

# Chronological split for Session 1
split_idx_s1 = int(len(X_s1) * TRAIN_SPLIT_RATIO)
X_s1_train, y_s1_train = X_s1.iloc[:split_idx_s1], y_s1[:split_idx_s1]
X_s1_test, y_s1_test = X_s1.iloc[split_idx_s1:], y_s1[split_idx_s1:]

# Chronological split for Session 2
split_idx_s2 = int(len(X_s2) * TRAIN_SPLIT_RATIO)
X_s2_train, y_s2_train = X_s2.iloc[:split_idx_s2], y_s2[:split_idx_s2]
X_s2_test, y_s2_test = X_s2.iloc[split_idx_s2:], y_s2[split_idx_s2:]

print(f"\nSplitting complete:")
print(f"  Session 1: {len(X_s1_train)} train epochs, {len(X_s1_test)} test epochs.")
print(f"  Session 2: {len(X_s2_train)} train epochs, {len(X_s2_test)} test epochs.")

# Combine the training sets
X_train_combined = pd.concat([X_s1_train, X_s2_train], ignore_index=True)
y_train_combined = np.concatenate([y_s1_train, y_s2_train])
print(f"\nCombined training set created. Total epochs: {len(X_train_combined)}")

# --- Part B: Training the Model on the Combined Dataset ---
print("\n" + "="*60 + "\n--- PART B: Training Model on Combined 70% Data ---\n" + "="*60)
# RandomForest is a good choice for a potentially more complex, combined dataset
model_to_train = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('selector', SelectKBest(f_regression, k=min(N_FEATURES_TO_SELECT, X_train_combined.shape[1]))),
    ('regressor', model_to_train)
])

print("Training the final model...")
pipeline.fit(X_train_combined, y_train_combined)
print("Model training complete.")

# --- Part C: Evaluating on Session 1 Holdout Set ---
print("\n" + "="*60 + "\n--- PART C: Evaluating on Held-Out 30% of Session 1 ---\n" + "="*60)
y_s1_pred = pipeline.predict(X_s1_test)
rmse_s1 = np.sqrt(mean_squared_error(y_s1_test, y_s1_pred)); mae_s1 = mean_absolute_error(y_s1_test, y_s1_pred); r2_s1 = r2_score(y_s1_test, y_s1_pred)

print("\n--- Performance on Session 1 Holdout ---")
print(f"  RMSE: {rmse_s1:.3f} mmol/L"); print(f"  MAE: {mae_s1:.3f} mmol/L"); print(f"  RÂ²: {r2_s1:.3f}")
plot_clarke_error_grid(y_s1_test, y_s1_pred, "Test on Session 1 Holdout", PLOTS_FOLDER)

# --- Part D: Evaluating on Session 2 Holdout Set ---
print("\n" + "="*60 + "\n--- PART D: Evaluating on Held-Out 30% of Session 2 ---\n" + "="*60)
y_s2_pred = pipeline.predict(X_s2_test)
rmse_s2 = np.sqrt(mean_squared_error(y_s2_test, y_s2_pred)); mae_s2 = mean_absolute_error(y_s2_test, y_s2_pred); r2_s2 = r2_score(y_s2_test, y_s2_pred)

print("\n--- Performance on Session 2 Holdout ---")
print(f"  RMSE: {rmse_s2:.3f} mmol/L"); print(f"  MAE: {mae_s2:.3f} mmol/L"); print(f"  RÂ²: {r2_s2:.3f}")
plot_clarke_error_grid(y_s2_test, y_s2_pred, "Test on Session 2 Holdout", PLOTS_FOLDER)

print("\n\nAll experiments complete!")